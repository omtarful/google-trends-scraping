{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Google Trends\n",
    "This code connects to google trends and created a function to convert terms to topic ids to perform topic search when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This lines connect to Google Trends\n",
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import re\n",
    "from itertools import product\n",
    "import requests\n",
    "import time\n",
    "\n",
    "#Sets up language to host language\n",
    "pytrends = TrendReq(hl='en-US')\n",
    "#function takes as input a keyword and returns topic id\n",
    "def getTopicID(word):\n",
    "    #get suggested searches for word\n",
    "    suggs = pytrends.suggestions(word)\n",
    "    #check each suggestion and see if contains a topic\n",
    "    for s in range(len(suggs)):\n",
    "        #if the type of suggestion is a topic, return the topic id\n",
    "        pattern = suggs[s].get(\"title\").lower() + \"(s|es|os)\"\n",
    "        if suggs[s].get(\"type\") == \"Topic\" and (suggs[s].get(\"title\").lower() == word.lower() or re.match(pattern, word.lower() )): \n",
    "            return(suggs[s].get(\"mid\"))\n",
    "    #returns None if there is no topic id\n",
    "    return word\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we choose the payload parameters for the request to be sent to the server. There are 5 different inputs to the payload like the original platform. Wrapped it in a function to get table for all topics and comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get interest over time depending on the region\n",
    "def get_interest_over_time(kw_list, kw_comp_list, timeframes, ct, geo, gprop):\n",
    "    #converts kw to ids to do topic look up\n",
    "    topicID_list = [getTopicID(kw) for kw in kw_list]\n",
    "    comp_topicID = [getTopicID(kw) for kw in kw_comp_list] \n",
    "    #keyword dictionary used to rename columns\n",
    "    #keys are ids, values are keywords\n",
    "    kw_dict = dict(zip(topicID_list, kw_list))\n",
    "    kw_dict.update(dict(zip(comp_topicID, kw_comp_list)))\n",
    "    objective_df = pd.DataFrame()\n",
    "    all_columns = topicID_list + [e for e in product(comp_topicID, topicID_list)]  \n",
    "    for column in all_columns:\n",
    "        term = [column] if isinstance(column, str) else column\n",
    "        #catches exception when there is a timeout on google trends\n",
    "        #it's useful to continue running after timeout\n",
    "        try:\n",
    "            pytrends.build_payload(\n",
    "                kw_list= term,\n",
    "                cat = 0,\n",
    "                timeframe = timeframes,\n",
    "                geo = \"IT\",\n",
    "                gprop = \"\"\n",
    "                    )\n",
    "            time.sleep(0) #wait some seconds before sending the next request\n",
    "            #for a larger number of requests it should wait 60s\n",
    "        except requests.exceptions.Timeout: \n",
    "            print(\"Timeout ocurred\")\n",
    "        partial_data = pytrends.interest_over_time() #data per column\n",
    "        partial_data = partial_data.drop(\"isPartial\", axis = 1) #deletes column that has partial data\n",
    "        #change column name \n",
    "        #2 cases\n",
    "        #2 columns\n",
    "        #if else statement to determine how to name columns\n",
    "        if(len(partial_data.columns) > 1):\n",
    "            #change column name to term_term2\n",
    "            partial_data.rename(columns = kw_dict, inplace=True)\n",
    "            new_col_names = {partial_data.columns[0]:(partial_data.columns[0] + \"_\" + partial_data.columns[1]),\n",
    "                            partial_data.columns[1]:(partial_data.columns[1] + \"_\" + partial_data.columns[0])}\n",
    "            partial_data.rename(columns = new_col_names, inplace=True)\n",
    "        if(len(partial_data.columns) == 1):\n",
    "            #change column name to term2_term\n",
    "            partial_data.rename(columns = kw_dict, inplace=True)\n",
    "        #1 columns  \n",
    "        objective_df = pd.concat([objective_df, partial_data], axis=1)\n",
    "    #changes formatting of date\n",
    "    objective_df.index = objective_df.index.to_period(\"M\")\n",
    "    return(objective_df)\n",
    "#italy dataframe\n",
    "#function accepts the following arguments\n",
    "#list of keywords used in the search\n",
    "kw_list = [\"Global warming\", \"climate change\", \"greenhouse gas\", \"renewable energy\", \n",
    "            \"sustainability\", \"Climate disaster\", \"green energy\", \"green investment\",\n",
    "            \"green production\"]  \n",
    "kw_comp_list = [\"Job\", \"health\", \"education\", \"drugs\"]\n",
    "#time frame\n",
    "timeframes = '2010-01-01 2021-12-31' \n",
    "#category \n",
    "ct = 0 #means all categories\n",
    "#geographical location\n",
    "geo = 'IT' #Italy\n",
    "gprop = '' #web search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets national data for italy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "italy_2010_monthly_df = get_interest_over_time(kw_list, kw_comp_list, timeframes, ct, geo, gprop)\n",
    "#italy monthly 2011 - 2021\n",
    "timeframes = '2011-01-01 2021-12-31' \n",
    "italy_2011_monthly_df = get_interest_over_time(kw_list, kw_comp_list, timeframes, ct, geo, gprop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data frame was created. Write into csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to csv file\n",
    "italy_2010_monthly_df.to_csv(\"italy_2010_monthly_interest_over_time.csv\")\n",
    "italy_2011_monthly_df.to_csv(\"italy_2011_monthly_interest_over_time.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates quarterly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_quartertly(df):\n",
    "    grouper = df.groupby([pd.Grouper(freq='Q')])\n",
    "    region_df_quarter = grouper.mean().reset_index()\n",
    "    #format date to look decent\n",
    "    return(region_df_quarter)\n",
    "italy_2010_quarterly_df = to_quartertly(italy_2010_monthly_df)\n",
    "italy_2011_quarterly_df = to_quartertly(italy_2011_monthly_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write quarterly data into csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "italy_2010_quarterly_df.to_csv(\"italy_2010_quarterly_interest_over_time.csv\", index=False)\n",
    "italy_2011_quarterly_df.to_csv(\"italy_2011_quarterly_interest_over_time.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are getting for each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regional_data(kw_list, kw_comp_list, timeframes, ct, geo, gprop):\n",
    "    #get regions\n",
    "    pytrends.build_payload(\n",
    "        kw_list= [kw_list[0]],\n",
    "        cat = 0,\n",
    "        timeframe = timeframes,\n",
    "        geo = \"IT\",\n",
    "        gprop = \"\"\n",
    "        )\n",
    "    #returns region ISO code\n",
    "    regions = pytrends.interest_by_region(inc_geo_code=True)\n",
    "    #extract region ISO code from df\n",
    "    geos = regions.geoCode\n",
    "    #create regional data frame\n",
    "    region_df = pd.DataFrame()\n",
    "    #gets interest over time for each region and then appends them together\n",
    "    for i in range(len(geos)):\n",
    "        regions = get_interest_over_time(kw_list, kw_comp_list, timeframes, ct, geos[i], gprop)\n",
    "        regions.insert(loc=0, column=\"Region\", value=geos.index[i])\n",
    "        region_df = region_df.append(regions)\n",
    "    return(region_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interest over time for every italy region starting from 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeframes = '2010-01-01 2021-12-31' \n",
    "italy_region_2010_monthly_interest_over_time = get_regional_data(kw_list, kw_comp_list, timeframes, ct, geo, gprop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swaps columns to place region before date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swap columns so date appears before region\n",
    "copy_italy_region_2010 = italy_region_2010_monthly_interest_over_time.copy()\n",
    "copy_italy_region_2010.insert(1, 'date', copy_italy_region_2010.index)\n",
    "copy_italy_region_2010.reset_index(drop = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writes result to csv file\n",
    "copy_italy_region_2010.to_csv(\"italy_region_2010_monthly_interest_over_time.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeframes = '2011-01-01 2021-12-31' \n",
    "italy_region_2011_monthly_interest_over_time = get_regional_data(kw_list, kw_comp_list, timeframes, ct, geo, gprop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swaps columns to place date after region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_italy_region_2011 = italy_region_2011_monthly_interest_over_time.copy()\n",
    "copy_italy_region_2011.insert(1, 'date', copy_italy_region_2011.index) #inserts date column at index 1\n",
    "copy_italy_region_2011.reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_italy_region_2011.to_csv(\"italy_region_2011_monthly_interest_over_time.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data to quarterly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts data to quarter and writes in csv file\n",
    "def to_quarter(df):\n",
    "    grouper = df.groupby([\"Region\", pd.Grouper(freq='Q')])\n",
    "    region_df_quarter = grouper.mean().reset_index()\n",
    "    return(region_df_quarter)\n",
    "to_quarter(copy_italy_region_2010).to_csv(\"italy_region_2010_quarterly_interest_over_time.csv\", index=False)\n",
    "to_quarter(copy_italy_region_2011).to_csv(\"italy_region_2011_quarterly_interest_over_time.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicID_list = [getTopicID(kw) for kw in kw_list]\n",
    "comp_topicID = [getTopicID(kw) for kw in kw_comp_list] \n",
    "#keyword dictionary used to rename columns\n",
    "#keys are ids, values are keywords\n",
    "kw_dict = dict(zip(topicID_list, kw_list))\n",
    "kw_dict.update(dict(zip(comp_topicID, kw_comp_list)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term search was done on these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate disaster\n",
      "green investment\n",
      "green production\n"
     ]
    }
   ],
   "source": [
    "for key in kw_dict:\n",
    "    if(key == kw_dict[key]):\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic search was done on these terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global warming\n",
      "climate change\n",
      "greenhouse gas\n",
      "renewable energy\n",
      "sustainability\n",
      "green energy\n",
      "Job\n",
      "health\n",
      "education\n",
      "drugs\n"
     ]
    }
   ],
   "source": [
    "for key in kw_dict:\n",
    "    if(key != kw_dict[key]):\n",
    "        print(kw_dict[key])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
